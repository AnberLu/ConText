#!/bin/bash
  ####  Input: token file (one review per line; tokens are delimited by white space): *.txt.tok
  ####         label file (one label per line): *.cat
  ####  These input files were generated by prep_elec.sh and included in the package. 

  #-----------------#
  gpu=-1  # <= change this to, e.g., "gpu=0" to use a specific GPU. 
  mem=4   # pre-allocate 4GB device memory. 
  source sh-common.sh
  #-----------------#
  nm=elec
  dir=elec # <= change this to where the Elec dataset is.  

  options="LowerCase UTF8"

  for sz in 05k 10k 50k 100k 200k; do
    #---  Step 1. Generate vocabulary
    echo Generaing vocabulary from training data ... $sz ... 

    max_num=30000
    vocab_fn=${tmpdir}/${nm}-${sz}_trn-${max_num}.vocab
  
    $prep_exe gen_vocab input_fn=${dir}/${nm}-${sz}-train.txt.tok vocab_fn=$vocab_fn max_vocab_size=$max_num \
                              $options WriteCount 
    if [ $? != 0 ]; then echo $shnm: gen_vocab failed.; exit 1; fi

    #---  Step 2. Generate region files (${tmpdir}/*.xsmatbcvar) and target files (${tmpdir}/*.y) for training and testing CNN.  
    #     We generate region vectors of the convolution layer and write them to a file, instead of making them 
    #     on the fly during training/testing.  
    echo 
    echo Generating region files ... $sz ... 
    for set in train test; do 
      for pch_sz in 3 4; do
        rnm=${tmpdir}/${nm}-${sz}_${set}-p${pch_sz}
        inp_fn=${dir}/${nm}-${sz}-${set}
        if [ "$set" = "test" ]; then
          inp_fn=data/${nm}-${set}
        fi

        #---  NOTE: The parameters are the same as IMDB.  
        $prep_exe gen_regions $options region_fn_stem=$rnm \
          input_fn=$inp_fn vocab_fn=$vocab_fn label_dic_fn=data/${nm}_cat.dic \
          patch_size=${pch_sz} padding=$((pch_sz-1))
        if [ $? != 0 ]; then echo $shnm: gen_regions failed.; exit 1; fi
      done
    done


    #---  Step 3. Training and test using GPU
    mynm=shcnn-seq2-${nm}-${sz}
    log_fn=${logdir}/${mynm}.log
    csv_fn=${csvdir}/${mynm}.csv
    echo 
    echo Training CNN and testing ... $sz ...
    echo This takes a while.  See $log_fn and $perf_fn for progress.  
    nodes=1000
    if [ "$sz" = "05k" ] || [ "$sz" = "10k" ]; then
      stepsize=0.5
    else
      stepsize=0.25
    fi

    $exe $gpu:$mem train trnname=${nm}-${sz}_train- tstname=${nm}-${sz}_test- \
         datatype=sparse dsno0=p3 dsno1=p4 data_dir=$tmpdir \
         loss=Square num_epochs=100 reg_L2=0 top_reg_L2=1e-3 top_dropout=0.5 \
         momentum=0.9 mini_batch_size=100 random_seed=1 \
         step_size=$stepsize ss_scheduler=Few ss_decay=0.1 ss_decay_at=80 \
         layers=2 conn=0-top,1-top ConcatConn \
         0layer_type=Weight+ 0dsno=0 \
         1layer_type=Weight+ 1dsno=1 \
         nodes=$nodes activ_type=Rect pooling_type=Max num_pooling=1 resnorm_type=Text \
         test_interval=25 evaluation_fn=$csv_fn > ${log_fn}
    if [ $? != 0 ]; then echo $shnm: traning failed.; exit 1; fi

    rm ${tmpdir}/${nm}-${sz}*
  done
