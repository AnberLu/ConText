#!/bin/bash
  ####  Input: token file (one review per line; tokens are delimited by white space) 
  ####         label file (one label per line)
  ####  These input files were generated by prep_imdb.sh and included in the package. 
  ####  To find the order of the data points, see prep_imdb.sh and the files at lst/. 

  #-----------------#
  gpu=-1  # <= change this to, e.g., "gpu=0" to use a specific GPU. 
  source sh-common.sh
  #-----------------#

  nm=imdb
  z=s23k

  #---  Step 1. Generate vocabulary
  echo Generaing vocabulary from training data ... 

  max_num=10000
  vocab_fn=${tmpdir}/${nm}${z}_trn-${max_num}.vocab
  options="LowerCase UTF8"

  $prep_exe gen_vocab input_fn=data/${nm}-train.txt.tok vocab_fn=$vocab_fn max_vocab_size=$max_num \
                            $options WriteCount
  if [ $? != 0 ]; then echo $shnm: gen_vocab failed.; exit 1; fi

  #---  Step 2. Generate region files (${tmpdir}/*.xsmatbcvar) and target files (${tmpdir}/*.y). 
  echo
  echo Generating region files with region size 2 and 3 ...  
  for pch_sz in 2 3; do
    for set in train test; do 
      rnm=${tmpdir}/${nm}${z}_${set}-10kp${pch_sz}
      $prep_exe gen_regions $options region_fn_stem=$rnm \
         input_fn=data/${nm}-${set} vocab_fn=$vocab_fn label_dic_fn=data/${nm}_cat.dic \
         patch_size=$pch_sz padding=$((pch_sz-1))
      if [ $? != 0 ]; then echo $shnm: gen_regions failed.; exit 1; fi
    done
  done


  #---  Step 3. Training and test using GPU
  mynm=shcnn-seq2-3k-${nm}
  log_fn=${logdir}/${mynm}.log
  csv_fn=${csvdir}/${mynm}.csv
  echo 
  echo Training CNN and testing ... 
  echo This takes a while.  See $log_fn and $perf_fn for progress. 
  $exe $gpu train datatype=sparse \
         data_dir=$tmpdir trnname=${nm}${z}_train- tstname=${nm}${z}_test- \
         dsno0=10kp2 dsno1=10kp3 \
         loss=Square num_epochs=100 \
         reg_L2=0 top_reg_L2=1e-3 top_dropout=0.5 \
         momentum=0.9 mini_batch_size=100 random_seed=1 \
         step_size=0.25 ss_scheduler=Few ss_decay=0.1 ss_decay_at=80 \
         layers=2 conn=0-top,1-top ConcatConn \
         0layer_type=Weight+ 0dsno=0 \
         1layer_type=Weight+ 1dsno=1 \
         nodes=3000 activ_type=Rect pooling_type=Max num_pooling=1 resnorm_type=Text \
         test_interval=25 evaluation_fn=$csv_fn > ${log_fn}
  if [ $? != 0 ]; then echo $shnm: training failed.; exit 1; fi

  rm -f ${tmpdir}/${nm}${z}*